{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Auto Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Plan\n",
    "1. Split data into gene and cell features\n",
    "2. Train a AE on each\n",
    "3. Use AE to generate latent features for gene and cell features\n",
    "4. Use to train ensemble (NN, LR, XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join, exists\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from pipeline.networks import create_dense_module\n",
    "from pipeline.utils import SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../data/train_features.csv')\n",
    "train_targets = pd.read_csv('../data/train_targets_scored.csv')\n",
    "train_targets_ns = pd.read_csv('../data/train_targets_nonscored.csv')\n",
    "test_features = pd.read_csv('../data/test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_features.columns if '-' in c]\n",
    "all_features = np.vstack([train_features[features].values, test_features[features].values])\n",
    "scaler = StandardScaler()\n",
    "features_t = scaler.fit_transform(all_features)\n",
    "scaler_2 = MinMaxScaler()\n",
    "features_t = scaler_2.fit_transform(features_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: -1, 48: 0, 72: 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    df = df.drop('cp_type', axis=1)\n",
    "    df.loc[:, features] = scaler_2.transform(scaler.transform(df.loc[:, features]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = process_df(train_features)\n",
    "test_features = process_df(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_features = [c for c in train_features.columns if 'g-' in c]\n",
    "cell_features = [c for c in train_features.columns if 'c-' in c]\n",
    "base_features = ['cp_time', 'cp_dose']\n",
    "gene_x = train_features[base_features + gene_features].values\n",
    "cell_x = train_features[base_features + cell_features].values\n",
    "y = train_targets.values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "\n",
    "    def load(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def add(self, x):\n",
    "        return self.data.append(x)\n",
    "\n",
    "    def mean(self):\n",
    "        return np.mean(self.data)\n",
    "\n",
    "    def min_epoch(self):\n",
    "        return np.argmin(self.data)\n",
    "\n",
    "    def min(self):\n",
    "        return np.min(self.data)\n",
    "\n",
    "    def max(self):\n",
    "        return np.max(self.data)\n",
    "\n",
    "    def tail(self):\n",
    "        return self.data[-1]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AutoEncoderDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        self.length = len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.x[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, feature_size, latent_layer_size, init_dropout, dropout, normalization, activation):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        bounds = (feature_size, latent_layer_size)\n",
    "        intermediate_layer_size = int(((max(bounds) - min(bounds)) / 2) + min(bounds))\n",
    "        \n",
    "        layers = []\n",
    "        layers.extend(create_dense_module(feature_size, intermediate_layer_size, init_dropout, normalization, activation))\n",
    "        layers.extend(create_dense_module(intermediate_layer_size, latent_layer_size, dropout, normalization, activation))\n",
    "        layers.extend(create_dense_module(latent_layer_size, intermediate_layer_size, dropout, normalization, activation))\n",
    "        layers.extend(create_dense_module(intermediate_layer_size, feature_size, dropout, normalization, activation=None))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform create_dense_module into nn.Module, then add nan fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     134,
     160,
     174,
     181,
     191
    ]
   },
   "outputs": [],
   "source": [
    "class NeuralNetModel:\n",
    "    def __init__(self, model_dict):\n",
    "        self.model_dict = model_dict\n",
    "        self.best_weights_path = join(self.model_dict['model_dir'], 'fold-%d-weights.pth' % self.model_dict['fold'])\n",
    "        self.epoch = 0\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.train_metrics = Metrics()\n",
    "        self.valid_metrics = Metrics()\n",
    "\n",
    "        if model_dict['normalization'] == 'batch':\n",
    "            model_dict['normalization'] = nn.BatchNorm1d\n",
    "        else:\n",
    "            Exception('Normalization not supported.')\n",
    "\n",
    "        if model_dict['activation'] == 'relu':\n",
    "            model_dict['activation'] = nn.ReLU\n",
    "        elif model_dict['activation'] == 'prelu':\n",
    "            model_dict['activation'] = nn.PReLU\n",
    "        else:\n",
    "            Exception('Activation not supported.')\n",
    "        \n",
    "        if model_dict['model'] == 'AutoEncoder':\n",
    "            self.model = AutoEncoder(\n",
    "                model_dict['feature_size'],\n",
    "                model_dict['latent_layer_size'],\n",
    "                model_dict['init_dropout'],\n",
    "                model_dict['dropout'],\n",
    "                model_dict['normalization'],\n",
    "                model_dict['activation'],\n",
    "            )\n",
    "\n",
    "        # Setup optimizer\n",
    "        if model_dict['optimizer'] == 'sgd':\n",
    "            self.optimizer = optim.SGD(self.model.parameters(),\n",
    "                                       lr=model_dict['learning_rate'],\n",
    "                                       momentum=model_dict['momentum'])\n",
    "        elif model_dict['optimizer'] == 'adam':\n",
    "            self.optimizer = optim.Adam(self.model.parameters(),\n",
    "                                        lr=model_dict['learning_rate'],\n",
    "                                        weight_decay=model_dict['weight_decay'])\n",
    "        else:\n",
    "            Exception('Optimizer not supported.')\n",
    "\n",
    "        # Setup scheduler\n",
    "        if model_dict['scheduler'] == 'ReduceLROnPlateau':\n",
    "            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer,\n",
    "                                                                  patience=3,\n",
    "                                                                  threshold=0.00001)\n",
    "        elif model_dict['scheduler'] == 'OneCycleLR':\n",
    "            self.scheduler = optim.lr_scheduler.OneCycleLR(self.optimizer,\n",
    "                                                           max_lr=0.01,\n",
    "                                                           pct_start=0.1,\n",
    "                                                           div_factor=1e3,\n",
    "                                                           epochs=model_dict['n_epochs'],\n",
    "                                                           steps_per_epoch=model_config['steps_per_epoch'])\n",
    "        else:\n",
    "            Exception('Scheduler not supported.')\n",
    "\n",
    "        # Save initial states of model, optimizer and scheduler\n",
    "        self.init_states = dict(\n",
    "            model=self.model.state_dict(),\n",
    "            optimizer=self.optimizer.state_dict(),\n",
    "            scheduler=self.scheduler.state_dict()\n",
    "        )\n",
    "        self.model = self.model.cuda()\n",
    "\n",
    "    def train_epoch(self, train_dataloader):\n",
    "        losses = []\n",
    "        self.model.train()\n",
    "\n",
    "        for features_c, features in train_dataloader:\n",
    "            features_c = features.cuda().float()\n",
    "            features = features.cuda().float()\n",
    "            predictions = self.model(features_c)\n",
    "            loss = self.criterion(predictions, features)\n",
    "            for p in self.model.parameters():\n",
    "                p.grad = None\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if self.model_dict['scheduler'] == 'OneCycleLR':\n",
    "                self.scheduler.step()\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "#         for features, targets, ids in train_dataloader:\n",
    "#             features = {k: v.cuda().float() for k, v in features.items()}\n",
    "#             targets = targets.cuda().float()\n",
    "#             predictions = self.model(features)\n",
    "#             loss = self.criterion(predictions, targets)\n",
    "#             for p in self.model.parameters():\n",
    "#                 p.grad = None\n",
    "#             if self.model_dict['use_amp']:\n",
    "#                 with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "#                     scaled_loss.backward()\n",
    "#             else:\n",
    "#                 loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#             if self.model_dict['scheduler'] == 'OneCycleLR':\n",
    "#                 self.scheduler.step()\n",
    "#             losses.append(loss.detach().cpu().numpy())\n",
    "        avg_loss = float(np.mean(losses))\n",
    "        self.train_metrics.add(avg_loss)\n",
    "        return avg_loss\n",
    "\n",
    "    def validation(self, valid_dataloader, return_preds=False):\n",
    "        losses = []\n",
    "        predictions = []\n",
    "        self.model.eval()\n",
    "\n",
    "        for features_c, features in valid_dataloader:\n",
    "            features_c = features_c.cuda().float()\n",
    "            features = features.cuda().float()\n",
    "            pred = self.model(features_c)\n",
    "            loss = self.criterion(pred, features)\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "            if return_preds:\n",
    "                predictions.extend(pred.detach().cpu().numpy())\n",
    "\n",
    "#         for features, targets, ids in valid_dataloader:\n",
    "#             features = {k: v.cuda().float() for k, v in features.items()}\n",
    "#             targets = targets.cuda().float()\n",
    "#             pred = self.model(features)\n",
    "#             loss = self.criterion(pred, targets)\n",
    "#             losses.append(loss.detach().cpu().numpy())\n",
    "#             if return_preds:\n",
    "#                 predictions.extend(pred.detach().cpu().numpy())\n",
    "\n",
    "        avg_loss = float(np.mean(losses))\n",
    "\n",
    "        if return_preds:\n",
    "            return avg_loss, predictions\n",
    "        else:\n",
    "            return avg_loss\n",
    "\n",
    "    def train(self, train_dataloader, valid_dataloader):\n",
    "        for epoch in range(self.model_dict['n_epochs']):\n",
    "            self.epoch = epoch\n",
    "            time0 = time.time()\n",
    "\n",
    "            train_avg_loss = self.train_epoch(train_dataloader)\n",
    "            valid_avg_loss = self.validation(valid_dataloader)\n",
    "\n",
    "            if self.epoch == 0 or valid_avg_loss < self.valid_metrics.min():\n",
    "                # new best weights\n",
    "                self.save(self.best_weights_path)\n",
    "            self.valid_metrics.add(valid_avg_loss)\n",
    "\n",
    "            if self.model_dict['scheduler'] != 'OneCycleLR':\n",
    "                self.scheduler.step(valid_avg_loss)\n",
    "\n",
    "            time1 = time.time()\n",
    "            epoch_time = time1 - time0\n",
    "            if self.model_dict['verbose']:\n",
    "                print('Epoch %d/%d Train Loss: %.5f Valid Loss: %.5f Time: %.2f' % (\n",
    "                    epoch+1, self.model_dict['n_epochs'], train_avg_loss, valid_avg_loss, epoch_time\n",
    "                ))\n",
    "\n",
    "        # restore weights from best epoch\n",
    "        self.load(self.best_weights_path)\n",
    "\n",
    "    def predict(self, test_features):\n",
    "        test_dataset = MoaDataset(test_features)\n",
    "        test_dataloader = DataLoader(test_dataset,\n",
    "                                     batch_size=self.model_dict['batch_size'],\n",
    "                                     num_workers=self.model_dict['num_workers'],\n",
    "                                     pin_memory=True)\n",
    "        predictions = []\n",
    "        self.model.eval()\n",
    "        for features, ids in test_dataloader:\n",
    "            features = {k: v.cuda().float() for k, v in features.items()}\n",
    "            pred = self.model(features)\n",
    "            predictions.extend(pred.detach().cpu().numpy())\n",
    "        return predictions\n",
    "\n",
    "    def reset(self):\n",
    "        self.model.load_state_dict(self.init_states['model'])\n",
    "        self.optimizer.load_state_dict(self.init_states['optimizer'])\n",
    "        self.scheduler.load_state_dict(self.init_states['scheduler'])\n",
    "        self.train_metrics.reset()\n",
    "        self.valid_metrics.reset()\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'scheduler': self.scheduler.state_dict(),\n",
    "            'train_metrics': self.train_metrics.data,\n",
    "            'valid_metrics': self.valid_metrics.data,\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        state_dict = torch.load(path)\n",
    "        self.model.load_state_dict(state_dict['model'])\n",
    "        self.optimizer.load_state_dict(state_dict['optimizer'])\n",
    "        self.scheduler.load_state_dict(state_dict['scheduler'])\n",
    "        self.train_metrics.load(state_dict['train_metrics'])\n",
    "        self.valid_metrics.load(state_dict['valid_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def initialize_bias(layers, init_bias):\n",
    "    weights = layers.state_dict()\n",
    "    last_layer_id = next(reversed(weights)).split('.')[0]\n",
    "    weights[last_layer_id + '.bias'] = torch.tensor(init_bias)\n",
    "    layers.load_state_dict(weights)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    model='AutoEncoder',\n",
    "    latent_layer_size=128,\n",
    "    init_dropout=0.2,\n",
    "    dropout=0.2,\n",
    "    normalization='batch',\n",
    "    activation='relu',\n",
    "    \n",
    "    n_epochs=25,\n",
    "    optimizer='adam',\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-4,\n",
    "    scheduler='OneCycleLR',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/envs/ml_py385/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass shuffle=True, random_state=123 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 Train Loss: 0.73320 Valid Loss: 0.69640 Time: 1.13\n",
      "Epoch 2/25 Train Loss: 0.67683 Valid Loss: 0.66528 Time: 1.05\n",
      "Epoch 3/25 Train Loss: 0.66265 Valid Loss: 0.66428 Time: 1.11\n",
      "Epoch 4/25 Train Loss: 0.65168 Valid Loss: 0.65927 Time: 1.08\n",
      "Epoch 5/25 Train Loss: 0.64165 Valid Loss: 0.64351 Time: 1.06\n",
      "Epoch 6/25 Train Loss: 0.63241 Valid Loss: 0.62544 Time: 1.09\n",
      "Epoch 7/25 Train Loss: 0.62011 Valid Loss: 0.61103 Time: 1.07\n",
      "Epoch 8/25 Train Loss: 0.60453 Valid Loss: 0.58984 Time: 1.09\n",
      "Epoch 9/25 Train Loss: 0.58591 Valid Loss: 0.57039 Time: 1.08\n",
      "Epoch 10/25 Train Loss: 0.56422 Valid Loss: 0.54597 Time: 1.03\n",
      "Epoch 11/25 Train Loss: 0.54031 Valid Loss: 0.50885 Time: 1.07\n",
      "Epoch 12/25 Train Loss: 0.51593 Valid Loss: 0.48485 Time: 1.05\n",
      "Epoch 13/25 Train Loss: 0.49158 Valid Loss: 0.47187 Time: 1.11\n",
      "Epoch 14/25 Train Loss: 0.46885 Valid Loss: 0.43491 Time: 1.08\n",
      "Epoch 15/25 Train Loss: 0.44655 Valid Loss: 0.42040 Time: 1.05\n",
      "Epoch 16/25 Train Loss: nan Valid Loss: nan Time: 1.10\n",
      "Epoch 17/25 Train Loss: nan Valid Loss: nan Time: 1.05\n",
      "Epoch 18/25 Train Loss: nan Valid Loss: nan Time: 1.03\n",
      "Epoch 19/25 Train Loss: nan Valid Loss: nan Time: 1.06\n",
      "Epoch 20/25 Train Loss: nan Valid Loss: nan Time: 1.05\n",
      "Epoch 21/25 Train Loss: nan Valid Loss: nan Time: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-145:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matthew/anaconda3/envs/ml_py385/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/matthew/anaconda3/envs/ml_py385/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/matthew/anaconda3/envs/ml_py385/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/matthew/anaconda3/envs/ml_py385/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/matthew/anaconda3/envs/ml_py385/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/matthew/anaconda3/envs/ml_py385/lib/python3.8/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/matthew/anaconda3/envs/ml_py385/lib/python3.8/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/matthew/anaconda3/envs/ml_py385/lib/python3.8/multiprocessing/connection.py\", line 502, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/matthew/anaconda3/envs/ml_py385/lib/python3.8/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-c0d453769177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-0d98086467d4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataloader, valid_dataloader)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mtime0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mtrain_avg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mvalid_avg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-0d98086467d4>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_dataloader)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scheduler'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'OneCycleLR'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_py385/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_py385/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train each autoencoder\n",
    "for x_label, x in dict(gene=gene_x, cell=cell_x).items():\n",
    "    \n",
    "    # Setup model directory\n",
    "    model_dir = join(SETTINGS['PROJECTS_DIR'], '%s_autoencoder' % x_label)\n",
    "    if not exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    # Split data into folds\n",
    "    skf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    for fold_i, (train_idx, valid_idx) in enumerate(skf.split(x, y)):\n",
    "        \n",
    "        # Setup dataloaders\n",
    "        train_x, valid_x = x[train_idx], x[valid_idx]\n",
    "        train_dataset = AutoEncoderDataset(train_x)\n",
    "        valid_dataset = AutoEncoderDataset(valid_x)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True, num_workers=4, shuffle=True)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, pin_memory=True, num_workers=4)\n",
    "\n",
    "        # Pass variables through model configuration\n",
    "        model_config['feature_size'] = train_x.shape[1]\n",
    "        model_config['model_dir'] = model_dir\n",
    "        model_config['fold'] = fold_i\n",
    "        model_config['steps_per_epoch'] = len(train_dataloader)\n",
    "\n",
    "        # Initialize model\n",
    "        model = NeuralNetModel(model_config)\n",
    "        \n",
    "        # Set custom init weights for fast convergence\n",
    "        init_bias = np.mean(train_x, axis=0)\n",
    "        model.model.layers = initialize_bias(model.model.layers, init_bias)\n",
    "        \n",
    "        # Train model\n",
    "        model.train(train_dataloader, valid_dataloader)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss, preds = model.validation(valid_dataloader, return_preds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = valid_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = nn.Sigmoid()(torch.tensor(preds[0])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(len(y0)), y0)\n",
    "plt.scatter(np.arange(len(y1)), y1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml 3.8.5)",
   "language": "python",
   "name": "ml_py385"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
